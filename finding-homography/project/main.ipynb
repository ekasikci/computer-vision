{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Width =  800\n",
      "Display Height =  600\n",
      "Original Width =  4032\n",
      "Original Height =  3024\n",
      "Selected points: [[174.  93.]\n",
      " [682. 171.]\n",
      " [  8. 306.]\n",
      " [685. 460.]]\n",
      "Selected points (original coordinates): [[ 876.96  468.72]\n",
      " [3437.28  861.84]\n",
      " [  40.32 1542.24]\n",
      " [3452.4  2318.4 ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homography with mouse click\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "selected_points = []\n",
    "\n",
    "# Function to handle mouse clicks\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global selected_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selected_points.append((x, y))\n",
    "        cv2.circle(param, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(\"Input Image\", param)\n",
    "\n",
    "input_image = cv2.imread(\"20230403_132407.jpg\")\n",
    "\n",
    "# Resize the input image to fit within the screen resolution\n",
    "max_width = 800  # Maximum width for display\n",
    "max_height = 600  # Maximum height for display\n",
    "aspect_ratio = input_image.shape[1] / input_image.shape[0]\n",
    "if aspect_ratio > 1:\n",
    "    display_width = min(max_width, input_image.shape[1])\n",
    "    display_height = int(display_width / aspect_ratio)\n",
    "else:\n",
    "    display_height = min(max_height, input_image.shape[0])\n",
    "    display_width = int(display_height * aspect_ratio)\n",
    "resized_image = cv2.resize(input_image, (display_width, display_height))\n",
    "\n",
    "cv2.imshow(\"Input Image\", resized_image)\n",
    "cv2.setMouseCallback(\"Input Image\", mouse_callback, resized_image)\n",
    "\n",
    "# Wait for four points to be selected\n",
    "while len(selected_points) < 4:\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "src_points_resized = np.array(selected_points, dtype=np.float32)\n",
    "\n",
    "print(\"Display Width = \", display_width)\n",
    "print(\"Display Height = \", display_height)\n",
    "print(\"Original Width = \", input_image.shape[1])\n",
    "print(\"Original Height = \", input_image.shape[0])\n",
    "\n",
    "print(\"Selected points:\", src_points_resized)\n",
    "\n",
    "# Scale selected points to represent original coordinates\n",
    "scale_x = input_image.shape[1] / resized_image.shape[1]\n",
    "scale_y = input_image.shape[0] / resized_image.shape[0]\n",
    "src_points = src_points_resized * np.array([scale_x, scale_y])\n",
    "\n",
    "print(\"Selected points (original coordinates):\", src_points)\n",
    "\n",
    "dst_points = np.array([[0, 0], [input_image.shape[1], 0], [0, input_image.shape[0]], [input_image.shape[1], input_image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "output_image = cv2.warpPerspective(input_image, homography_matrix, (input_image.shape[1], input_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Homography_mouse_selected.jpg\", output_image)\n",
    "\n",
    "# Convert the homography image back to the original format\n",
    "homography_matrix, _ = cv2.findHomography(dst_points, src_points)\n",
    "\n",
    "reversed_output_image = cv2.warpPerspective(output_image, homography_matrix, (output_image.shape[1], output_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Reversed_homography_mouse_selected.jpg\", reversed_output_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:56:47.276099700Z",
     "start_time": "2024-04-09T19:56:39.761660100Z"
    }
   },
   "id": "8b167503f188df73"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ekasi\\AppData\\Local\\Temp\\ipykernel_314452\\522126478.py:24: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  corners = np.int0(corners)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leftmost Up Corner: [243, 98]\n",
      "Leftmost Bottom Corner: [88, 278]\n",
      "Rightmost Up Corner: [689, 228]\n",
      "Rightmost Bottom Corner: [607, 492]\n",
      "Selected points: [[1399.68  564.48]\n",
      " [3968.64 1313.28]\n",
      " [ 506.88 1601.28]\n",
      " [3496.32 2833.92]]\n",
      "Destination points: [[   0.    0.]\n",
      " [4608.    0.]\n",
      " [   0. 3456.]\n",
      " [4608. 3456.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homography with corner detection\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "input_image = cv2.imread(\"IMG_20200316_171750.jpg\")\n",
    "\n",
    "# Resize the input image to fit within the screen resolution\n",
    "max_width = 800  # Maximum width for display\n",
    "max_height = 600  # Maximum height for display\n",
    "aspect_ratio = input_image.shape[1] / input_image.shape[0]\n",
    "if aspect_ratio > 1:\n",
    "    display_width = min(max_width, input_image.shape[1])\n",
    "    display_height = int(display_width / aspect_ratio)\n",
    "else:\n",
    "    display_height = min(max_height, input_image.shape[0])\n",
    "    display_width = int(display_height * aspect_ratio)\n",
    "resized_image = cv2.resize(input_image, (display_width, display_height))\n",
    "\n",
    "gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Detect corners\n",
    "corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10)\n",
    "corners = np.int0(corners)\n",
    "\n",
    "leftmost_up = [float('inf'), float('inf')]\n",
    "leftmost_bottom = [float('inf'), -float('inf')]\n",
    "rightmost_up = [-float('inf'), float('inf')]\n",
    "rightmost_bottom = [-float('inf'), -float('inf')]\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    \n",
    "    if y < leftmost_up[1]:\n",
    "        leftmost_up = [x, y]\n",
    "\n",
    "    if x < leftmost_bottom[0]:\n",
    "        leftmost_bottom = [x, y]\n",
    "\n",
    "    if x > rightmost_up[0]:\n",
    "        rightmost_up = [x, y]\n",
    "\n",
    "    if y > rightmost_bottom[1]:\n",
    "        rightmost_bottom = [x, y]\n",
    "\n",
    "print(\"Leftmost Up Corner:\", leftmost_up)\n",
    "print(\"Leftmost Bottom Corner:\", leftmost_bottom)\n",
    "print(\"Rightmost Up Corner:\", rightmost_up)\n",
    "print(\"Rightmost Bottom Corner:\", rightmost_bottom)\n",
    "\n",
    "# Scale selected points to represent original coordinates\n",
    "scale_x = input_image.shape[1] / resized_image.shape[1]\n",
    "scale_y = input_image.shape[0] / resized_image.shape[0]\n",
    "\n",
    "src_points = np.array([leftmost_up, rightmost_up, leftmost_bottom, rightmost_bottom], dtype=np.float32)\n",
    "\n",
    "src_points = src_points * np.array([scale_x, scale_y])\n",
    "\n",
    "print(\"Selected points:\", src_points)\n",
    "\n",
    "dst_points = np.array([[0, 0], [input_image.shape[1], 0], [0, input_image.shape[0]], [input_image.shape[1], input_image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "print(\"Destination points:\", dst_points)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "output_image = cv2.warpPerspective(input_image, homography_matrix, (input_image.shape[1], input_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Homography_corner_detected.jpg\", output_image)\n",
    "\n",
    "# Convert the homography image back to the original format\n",
    "homography_matrix, _ = cv2.findHomography(dst_points, src_points)\n",
    "\n",
    "reversed_output_image = cv2.warpPerspective(output_image, homography_matrix, (output_image.shape[1], output_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Reversed_homography_corner_detected.jpg\", reversed_output_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:58:30.372884100Z",
     "start_time": "2024-04-09T19:58:29.755669800Z"
    }
   },
   "id": "f3940c3121fe7f7"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Homography with color detection\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])  # BGR values\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hue = hsvC[0][0][0]  # Get the hue value\n",
    "\n",
    "    if hue >= 165:  # Upper limit for divided red hue\n",
    "        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([180, 255, 255], dtype=np.uint8)\n",
    "    elif hue <= 15:  # Lower limit for divided red hue\n",
    "        lowerLimit = np.array([0, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "    else:\n",
    "        lowerLimit = np.array([hue - 10, 100, 100], dtype=np.uint8)\n",
    "        upperLimit = np.array([hue + 10, 255, 255], dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit\n",
    "\n",
    "image = cv2.imread('colored_field.jpg')\n",
    "\n",
    "hsvImage = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Colors and their corresponding BGR values\n",
    "colors = {\n",
    "    'red': [0, 0, 255],\n",
    "    'yellow': [0, 255, 255],\n",
    "    'green': [0, 255, 0],\n",
    "    'blue': [255, 0, 0]\n",
    "}\n",
    "\n",
    "color_locations = {}\n",
    "\n",
    "for color_name, color_value in colors.items():\n",
    "    lowerLimit, upperLimit = get_limits(color_value)\n",
    "\n",
    "    mask = cv2.inRange(hsvImage, lowerLimit, upperLimit)\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    color_locations[color_name] = []\n",
    "\n",
    "    for contour in contours:\n",
    "        bbox = cv2.boundingRect(contour)\n",
    "        color_locations[color_name].append(bbox)\n",
    "\n",
    "src_points = np.array([color_locations['red'][0][:2], color_locations['yellow'][0][:2],\n",
    "                       color_locations['green'][0][:2], color_locations['blue'][0][:2]], dtype=np.float32)\n",
    "dst_points = np.array([[0, 0], [image.shape[1], 0], [0, image.shape[0]], [image.shape[1], image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "output_image = cv2.warpPerspective(image, homography_matrix, (image.shape[1], image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Homography_color_detected.jpg\", output_image)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T19:57:16.610058500Z",
     "start_time": "2024-04-09T19:57:16.029723700Z"
    }
   },
   "id": "5931e7eb75078d1f"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display Width =  800\n",
      "Display Height =  600\n",
      "Original Width =  4032\n",
      "Original Height =  3024\n",
      "Selected points: [[173.  93.]\n",
      " [682. 170.]\n",
      " [  9. 304.]\n",
      " [682. 457.]]\n",
      "Selected points (original coordinates): [[ 871.92  468.72]\n",
      " [3437.28  856.8 ]\n",
      " [  45.36 1532.16]\n",
      " [3437.28 2303.28]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Player detection with mouse click\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "selected_points = []\n",
    "\n",
    "# Function to handle mouse clicks\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global selected_points\n",
    "    \n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selected_points.append((x, y))\n",
    "        cv2.circle(param, (x, y), 5, (0, 255, 0), -1)\n",
    "        cv2.imshow(\"Input Image\", param)\n",
    "\n",
    "input_image = cv2.imread(\"20230403_132407.jpg\")\n",
    "\n",
    "# Resize the input image to fit within the screen resolution\n",
    "max_width = 800  # Maximum width for display\n",
    "max_height = 600  # Maximum height for display\n",
    "aspect_ratio = input_image.shape[1] / input_image.shape[0]\n",
    "if aspect_ratio > 1:\n",
    "    display_width = min(max_width, input_image.shape[1])\n",
    "    display_height = int(display_width / aspect_ratio)\n",
    "else:\n",
    "    display_height = min(max_height, input_image.shape[0])\n",
    "    display_width = int(display_height * aspect_ratio)\n",
    "resized_image = cv2.resize(input_image, (display_width, display_height))\n",
    "\n",
    "cv2.imshow(\"Input Image\", resized_image)\n",
    "cv2.setMouseCallback(\"Input Image\", mouse_callback, resized_image)\n",
    "\n",
    "# Wait for four points to be selected\n",
    "while len(selected_points) < 4:\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "src_points_resized = np.array(selected_points, dtype=np.float32)\n",
    "\n",
    "print(\"Display Width = \", display_width)\n",
    "print(\"Display Height = \", display_height)\n",
    "print(\"Original Width = \", input_image.shape[1])\n",
    "print(\"Original Height = \", input_image.shape[0])\n",
    "\n",
    "print(\"Selected points:\", src_points_resized)\n",
    "\n",
    "# Scale selected points to represent original coordinates\n",
    "scale_x = input_image.shape[1] / resized_image.shape[1]\n",
    "scale_y = input_image.shape[0] / resized_image.shape[0]\n",
    "src_points = src_points_resized * np.array([scale_x, scale_y])\n",
    "\n",
    "print(\"Selected points (original coordinates):\", src_points)\n",
    "\n",
    "dst_points = np.array([[0, 0], [input_image.shape[1], 0], [0, input_image.shape[0]], [input_image.shape[1], input_image.shape[0]]], dtype=np.float32)\n",
    "\n",
    "homography_matrix, _ = cv2.findHomography(src_points, dst_points)\n",
    "\n",
    "output_image = cv2.warpPerspective(input_image, homography_matrix, (input_image.shape[1], input_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Player_detection_first_homography.jpg\", output_image)\n",
    "\n",
    "# Function to check if a point is too close to any of the existing circles\n",
    "def eliminate_close_features(new_circle_center, existing_circle_centers, min_distance):\n",
    "    for center in existing_circle_centers:\n",
    "        if np.linalg.norm(np.array(new_circle_center) - np.array(center)) < min_distance:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(output_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([100, 50, 50])  \n",
    "upper_blue = np.array([140, 255, 255]) \n",
    "\n",
    "# Create a mask to extract only the blue regions in the image\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# List to store the centers of already drawn circles\n",
    "existing_circle_centers = []\n",
    "\n",
    "\n",
    "# Draw circles below the detected contours (assuming contours represent players)\n",
    "for contour in contours:\n",
    "    # Find the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "    # Calculate the center of the bottom edge of the bounding box\n",
    "    bottom_center = (x + w // 2, y + h)\n",
    "    \n",
    "    # Check if the new circle is too close to any existing circle\n",
    "    if not eliminate_close_features((cx, cy + 30), existing_circle_centers, min_distance=1500):\n",
    "        # Draw a circle below the bottom center\n",
    "        cv2.circle(output_image, bottom_center, 30, (0, 0, 255), 600)\n",
    "        \n",
    "        # Add the center of the newly drawn circle to the list of existing centers\n",
    "        existing_circle_centers.append(bottom_center)\n",
    "\n",
    "# Convert the homography image back to the original format\n",
    "homography_matrix, _ = cv2.findHomography(dst_points, src_points)\n",
    "\n",
    "reversed_output_image = cv2.warpPerspective(output_image, homography_matrix, (output_image.shape[1], output_image.shape[0]))\n",
    "\n",
    "cv2.imwrite(\"Reversed_player_detected.jpg\", reversed_output_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:00:34.415175600Z",
     "start_time": "2024-04-09T20:00:27.670205900Z"
    }
   },
   "id": "6b109eb008ed2c31"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Player detection without homography\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to check if a point is too close to any of the existing circles\n",
    "def eliminate_close_features(new_circle_center, existing_circle_centers, min_distance):\n",
    "    for center in existing_circle_centers:\n",
    "        if np.linalg.norm(np.array(new_circle_center) - np.array(center)) < min_distance:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "input_image = cv2.imread(\"20230403_132407.jpg\")\n",
    "\n",
    "# Convert the image to HSV color space\n",
    "hsv = cv2.cvtColor(input_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "lower_blue = np.array([100, 50, 50])  \n",
    "upper_blue = np.array([140, 255, 255]) \n",
    "\n",
    "# Create a mask to extract only the blue regions in the image\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "# Find contours in the mask\n",
    "contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# List to store the centers of already drawn circles\n",
    "existing_circle_centers = []\n",
    "\n",
    "# Draw circles below the detected contours (assuming contours represent players)\n",
    "for contour in contours:\n",
    "    # Find the bounding box of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    \n",
    "    M = cv2.moments(contour)\n",
    "    if M[\"m00\"] != 0:\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "        \n",
    "    # Calculate the center of the bottom edge of the bounding box\n",
    "    bottom_center = (x + w // 2, y + h)\n",
    "    \n",
    "    # Check if the new circle is too close to any existing circle\n",
    "    if not eliminate_close_features((cx, cy + 30), existing_circle_centers, min_distance=1000):\n",
    "        # Draw a circle below the bottom center\n",
    "        cv2.circle(input_image, bottom_center, 30, (0, 0, 255), 450)\n",
    "        \n",
    "        # Add the center of the newly drawn circle to the list of existing centers\n",
    "        existing_circle_centers.append(bottom_center)\n",
    "        \n",
    "cv2.imwrite(\"Player_detected.jpg\", input_image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T20:05:37.366344400Z",
     "start_time": "2024-04-09T20:05:37.043917100Z"
    }
   },
   "id": "51b840c5e79183da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c351dd338e87b3c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
