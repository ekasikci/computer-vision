{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-30T18:30:43.284697Z",
     "start_time": "2024-05-30T17:31:38.010940Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import sklearn.metrics\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Recognizer:\n",
    "    def __init__(self):\n",
    "        # Initialize the class with the names of the objects to recognize\n",
    "        self.nameOfClasses = [\"toothbrush_4\", \"shampoo_6\", \"onion_1\", \"marker_6\", \"hand_towel_5\", \"garlic_4\", \"food_box_11\", \"cereal_box_5\", \"calculator_1\", \"bell_pepper_2\"]\n",
    "        self.label_encoder = LabelEncoder()  \n",
    "        self.label_encoder.fit(self.nameOfClasses)  # Fit the label encoder with the class names\n",
    "        self.datasetDirectory = os.path.join(os.getcwd(), \"datasets\")  # Path to the datasets directory\n",
    "        self.outputDirectory = os.path.join(os.getcwd(), \"output\")  # Path to the output directory for saving keypoint visualizations\n",
    "        os.makedirs(self.outputDirectory, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "        self.trainingSet = {}  # Dictionary to hold training images for each class\n",
    "        self.testSet = {}  # Dictionary to hold testing images for each class\n",
    "        self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        # Check if the dataset directory exists\n",
    "        if not os.path.exists(self.datasetDirectory):\n",
    "            print(f\"Dataset directory {self.datasetDirectory} does not exist.\")\n",
    "            return\n",
    "\n",
    "        # Load images for each class\n",
    "        for obj in self.nameOfClasses:\n",
    "            images = self.load_images(obj)\n",
    "            if len(images) < 2:\n",
    "                print(f\"Skipping {obj} due to insufficient images.\")\n",
    "                continue\n",
    "            # Split the images into training and testing sets\n",
    "            train_images, test_images = train_test_split(images, test_size=0.1, random_state=42)\n",
    "            self.trainingSet[obj] = train_images\n",
    "            self.testSet[obj] = test_images\n",
    "        print(\"Data loading complete.\")\n",
    "        \n",
    "        # Balance the training data by ensuring each class has the same number of images\n",
    "        min_images = min(len(self.trainingSet[obj]) for obj in self.nameOfClasses)\n",
    "        for obj in self.nameOfClasses:\n",
    "            self.trainingSet[obj] = self.trainingSet[obj][:min_images]\n",
    "        print(\"Balanced training data\")\n",
    "\n",
    "    def load_images(self, object_name):\n",
    "        images = []\n",
    "        object_directory = os.path.join(self.datasetDirectory, object_name)\n",
    "        \n",
    "        # Check if the object directory exists\n",
    "        if not os.path.exists(object_directory):\n",
    "            print(f\"Object directory {object_directory} does not exist.\")\n",
    "            return images\n",
    "        \n",
    "        # Load images from the object directory\n",
    "        for img_path in glob.glob(os.path.join(object_directory, \"*_crop.png\")):\n",
    "            img = cv.imread(img_path)\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "        print(f\"Loaded {len(images)} images for {object_name}\")\n",
    "        return images\n",
    "\n",
    "    def detect_and_compute(self, image, method='orb', visualize=False, output_path=None):\n",
    "        # Convert the image to grayscale\n",
    "        grayscaleImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "        # Initialize the feature detector based on the specified method\n",
    "        if method == 'orb':\n",
    "            detector = cv.ORB_create()\n",
    "        elif method == 'brisk':\n",
    "            detector = cv.BRISK_create()\n",
    "        elif method == 'akaze':\n",
    "            detector = cv.AKAZE_create()\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported method: {method}\")\n",
    "        # Detect keypoints and compute descriptors\n",
    "        keypoints, descriptors = detector.detectAndCompute(grayscaleImage, None)\n",
    "        \n",
    "        # Visualize and save keypoints if requested\n",
    "        if visualize and output_path:\n",
    "            image_with_keypoints = cv.drawKeypoints(image, keypoints, None, color=(0, 255, 0))\n",
    "            cv.imwrite(output_path, image_with_keypoints)\n",
    "        \n",
    "        return keypoints, descriptors\n",
    "\n",
    "    def extract_features(self, method='orb'):\n",
    "        descriptors_list = []\n",
    "        labels = []\n",
    "        descriptor_lengths = []\n",
    "        # Extract features for each class in the training set\n",
    "        for label, images in self.trainingSet.items():\n",
    "            for img in images:\n",
    "                # Generate the output path for saving keypoint visualizations\n",
    "                output_path = os.path.join(self.outputDirectory, f\"{label}_{method}.png\")\n",
    "                keypoints, descriptors = self.detect_and_compute(img, method, visualize=True, output_path=output_path)\n",
    "                if descriptors is not None:\n",
    "                    descriptors_list.append(descriptors)\n",
    "                    labels.extend([self.label_encoder.transform([label])[0]] * len(descriptors))\n",
    "                    descriptor_lengths.append(len(descriptors))\n",
    "        \n",
    "        # Display some statistics about the descriptors\n",
    "        print(f\"Method: {method}\")\n",
    "        print(f\"Number of images: {len(descriptor_lengths)}\")\n",
    "        print(f\"Average number of descriptors per image: {np.mean(descriptor_lengths)}\")\n",
    "        print(f\"Descriptor dimensions: {descriptors_list[0].shape[1] if descriptors_list else 'N/A'}\")\n",
    "        \n",
    "        # Return the combined descriptors and corresponding labels\n",
    "        if descriptors_list:\n",
    "            return np.vstack(descriptors_list), np.array(labels)\n",
    "        else:\n",
    "            return np.array([]), np.array([])\n",
    "\n",
    "    def train(self, method='orb', n_clusters=128):\n",
    "        # Extract features from the training set\n",
    "        descriptors, labels = self.extract_features(method)\n",
    "        if descriptors.size == 0:\n",
    "            return None, None, None\n",
    "        # Scale the descriptors\n",
    "        scaler = sklearn.preprocessing.StandardScaler()\n",
    "        scaled_descriptors = scaler.fit_transform(descriptors)\n",
    "        # Perform k-means clustering on the scaled descriptors\n",
    "        kmeans = sklearn.cluster.KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        kmeans.fit(scaled_descriptors)\n",
    "        \n",
    "        # Map the cluster labels to class labels\n",
    "        cluster_to_class = self.map_clusters_to_labels(kmeans.labels_, labels)\n",
    "        return kmeans, scaler, cluster_to_class\n",
    "\n",
    "    def map_clusters_to_labels(self, cluster_labels, true_labels):\n",
    "        # Create a mapping from cluster labels to class labels\n",
    "        cluster_to_class = {}\n",
    "        for cluster in np.unique(cluster_labels):\n",
    "            indices = np.where(cluster_labels == cluster)\n",
    "            most_common_label = np.bincount(true_labels[indices]).argmax()\n",
    "            cluster_to_class[cluster] = most_common_label\n",
    "        return cluster_to_class\n",
    "\n",
    "    def predict(self, kmeans, scaler, cluster_to_class, method='orb'):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        # Predict the class for each image in the test set\n",
    "        for label, images in self.testSet.items():\n",
    "            for img in images:\n",
    "                keypoints, descriptors = self.detect_and_compute(img, method)\n",
    "                if descriptors is not None:\n",
    "                    scaled_descriptors = scaler.transform(descriptors)\n",
    "                    cluster_labels = kmeans.predict(scaled_descriptors)\n",
    "                    predicted_labels = [cluster_to_class.get(cluster, -1) for cluster in cluster_labels]\n",
    "                    predicted_label = self.majority_vote(predicted_labels)\n",
    "                    y_true.append(self.label_encoder.transform([label])[0])\n",
    "                    y_pred.append(predicted_label)\n",
    "        return y_true, y_pred\n",
    "\n",
    "    def majority_vote(self, labels):\n",
    "        # Return the most common label in the list\n",
    "        if len(labels) == 0:\n",
    "            return -1  # Return an invalid class if no descriptors found\n",
    "        counts = np.bincount(labels)\n",
    "        most_common_label = np.argmax(counts)\n",
    "        return most_common_label\n",
    "\n",
    "    def evaluate(self, method='orb', n_clusters=128):\n",
    "        # Train the model and evaluate its performance\n",
    "        kmeans, scaler, cluster_to_class = self.train(method, n_clusters)\n",
    "        if kmeans is None or scaler is None or cluster_to_class is None:\n",
    "            print(f\"Training failed for method: {method}\")\n",
    "            return 0.0, np.zeros((len(self.nameOfClasses), len(self.nameOfClasses)))\n",
    "\n",
    "        y_true, y_pred = self.predict(kmeans, scaler, cluster_to_class, method)\n",
    "        \n",
    "        accuracy = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "        confusion_matrix = sklearn.metrics.confusion_matrix(y_true, y_pred, labels=np.arange(len(self.nameOfClasses)))\n",
    "        return accuracy, confusion_matrix\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    recognizer = Recognizer()  # Initialize the recognizer\n",
    "    methods = ['orb', 'brisk', 'akaze']  # Define the methods to evaluate\n",
    "    cluster_sizes = [4096]  # Define the number of clusters for k-means\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Evaluate the model for each method and cluster size\n",
    "    for method in methods:\n",
    "        for n_clusters in cluster_sizes:\n",
    "            accuracy, confusion_matrix = recognizer.evaluate(method, n_clusters)\n",
    "            results.append((method, n_clusters, accuracy, confusion_matrix))\n",
    "\n",
    "    # Print the summarized results\n",
    "    for method, n_clusters, accuracy, confusion_matrix in results:\n",
    "        print(f\"Method: {method}, Clusters: {n_clusters}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(\"Confusion Matrix:\")\n",
    "        if confusion_matrix.shape == (len(recognizer.nameOfClasses), len(recognizer.nameOfClasses)):\n",
    "            print(pd.DataFrame(confusion_matrix, index=recognizer.nameOfClasses, columns=recognizer.nameOfClasses))\n",
    "        else:\n",
    "            print(\"Confusion matrix size does not match the number of classes.\")\n",
    "        print(\"\\n\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 583 images for toothbrush_4\n",
      "Loaded 799 images for shampoo_6\n",
      "Loaded 772 images for onion_1\n",
      "Loaded 807 images for marker_6\n",
      "Loaded 786 images for hand_towel_5\n",
      "Loaded 789 images for garlic_4\n",
      "Loaded 782 images for food_box_11\n",
      "Loaded 542 images for cereal_box_5\n",
      "Loaded 580 images for calculator_1\n",
      "Loaded 658 images for bell_pepper_2\n",
      "Data loading complete.\n",
      "Balanced training data\n",
      "Method: orb\n",
      "Number of images: 2475\n",
      "Average number of descriptors per image: 128.30989898989898\n",
      "Descriptor dimensions: 32\n",
      "Method: brisk\n",
      "Number of images: 3256\n",
      "Average number of descriptors per image: 89.79791154791155\n",
      "Descriptor dimensions: 64\n",
      "Method: akaze\n",
      "Number of images: 2326\n",
      "Average number of descriptors per image: 35.013757523645744\n",
      "Descriptor dimensions: 61\n",
      "Method: orb, Clusters: 4096\n",
      "Accuracy: 0.5045\n",
      "Confusion Matrix:\n",
      "               toothbrush_4  shampoo_6  onion_1  marker_6  hand_towel_5  \\\n",
      "toothbrush_4              2          2        4        12             0   \n",
      "shampoo_6                 0         21       32         3             0   \n",
      "onion_1                   0          0       54         1             0   \n",
      "marker_6                  0          0        1        78             0   \n",
      "hand_towel_5              0          0        0         0             0   \n",
      "garlic_4                  0          6       15         1             0   \n",
      "food_box_11               0          0       20         3             0   \n",
      "cereal_box_5              0          0        5         1             0   \n",
      "calculator_1              0          2       39         5             0   \n",
      "bell_pepper_2             0          0       14         1             0   \n",
      "\n",
      "               garlic_4  food_box_11  cereal_box_5  calculator_1  \\\n",
      "toothbrush_4          0            0             0             0   \n",
      "shampoo_6             0            0             0             0   \n",
      "onion_1               0            0             0             0   \n",
      "marker_6              0            0             0             0   \n",
      "hand_towel_5          0            0             0             0   \n",
      "garlic_4              0            0             0             0   \n",
      "food_box_11           0            9             0             0   \n",
      "cereal_box_5          0            0             0             0   \n",
      "calculator_1          0            0             0             0   \n",
      "bell_pepper_2         0            0             0             0   \n",
      "\n",
      "               bell_pepper_2  \n",
      "toothbrush_4               0  \n",
      "shampoo_6                  0  \n",
      "onion_1                    0  \n",
      "marker_6                   0  \n",
      "hand_towel_5               0  \n",
      "garlic_4                   0  \n",
      "food_box_11                0  \n",
      "cereal_box_5               0  \n",
      "calculator_1               0  \n",
      "bell_pepper_2              6  \n",
      "\n",
      "\n",
      "Method: brisk, Clusters: 4096\n",
      "Accuracy: 0.6523\n",
      "Confusion Matrix:\n",
      "               toothbrush_4  shampoo_6  onion_1  marker_6  hand_towel_5  \\\n",
      "toothbrush_4              0          3        8        12             0   \n",
      "shampoo_6                 0         58        0         0             0   \n",
      "onion_1                   0          0       54         1             0   \n",
      "marker_6                  0          0        0        79             0   \n",
      "hand_towel_5              0          1        4         1             0   \n",
      "garlic_4                  0         23       16         8             0   \n",
      "food_box_11               0          0       10         2             0   \n",
      "cereal_box_5              0          1        2         3             0   \n",
      "calculator_1              0         16       34         3             0   \n",
      "bell_pepper_2             0          1        1         1             0   \n",
      "\n",
      "               garlic_4  food_box_11  cereal_box_5  calculator_1  \\\n",
      "toothbrush_4          0            2             0             0   \n",
      "shampoo_6             0            0             0             0   \n",
      "onion_1               0            0             0             0   \n",
      "marker_6              0            0             0             0   \n",
      "hand_towel_5          0            0             0             1   \n",
      "garlic_4              9            0             0             0   \n",
      "food_box_11           0           55             0             0   \n",
      "cereal_box_5          0            0             0             0   \n",
      "calculator_1          0            1             0            11   \n",
      "bell_pepper_2         0            3             0             0   \n",
      "\n",
      "               bell_pepper_2  \n",
      "toothbrush_4               0  \n",
      "shampoo_6                  0  \n",
      "onion_1                    0  \n",
      "marker_6                   0  \n",
      "hand_towel_5               2  \n",
      "garlic_4                   1  \n",
      "food_box_11                0  \n",
      "cereal_box_5               0  \n",
      "calculator_1               0  \n",
      "bell_pepper_2             36  \n",
      "\n",
      "\n",
      "Method: akaze, Clusters: 4096\n",
      "Accuracy: 0.8500\n",
      "Confusion Matrix:\n",
      "               toothbrush_4  shampoo_6  onion_1  marker_6  hand_towel_5  \\\n",
      "toothbrush_4              5          1        2         1             0   \n",
      "shampoo_6                 0         54        1         3             0   \n",
      "onion_1                   0          0       54         0             0   \n",
      "marker_6                  0          0        0        79             0   \n",
      "hand_towel_5              0          0        0         0             0   \n",
      "garlic_4                  0          4        4         3             0   \n",
      "food_box_11               0          1        2         1             0   \n",
      "cereal_box_5              0          0        0         0             0   \n",
      "calculator_1              0          6        9         1             0   \n",
      "bell_pepper_2             0          2        2         0             0   \n",
      "\n",
      "               garlic_4  food_box_11  cereal_box_5  calculator_1  \\\n",
      "toothbrush_4          0            0             0             0   \n",
      "shampoo_6             0            0             0             0   \n",
      "onion_1               0            0             0             0   \n",
      "marker_6              0            0             0             0   \n",
      "hand_towel_5          0            0             0             0   \n",
      "garlic_4              1            0             0             0   \n",
      "food_box_11           0           21             0             0   \n",
      "cereal_box_5          0            0             0             0   \n",
      "calculator_1          0            0             0            22   \n",
      "bell_pepper_2         0            0             0             1   \n",
      "\n",
      "               bell_pepper_2  \n",
      "toothbrush_4               0  \n",
      "shampoo_6                  0  \n",
      "onion_1                    0  \n",
      "marker_6                   0  \n",
      "hand_towel_5               0  \n",
      "garlic_4                   0  \n",
      "food_box_11                1  \n",
      "cereal_box_5               0  \n",
      "calculator_1               0  \n",
      "bell_pepper_2             19  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "182a8493dcf34bf6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
